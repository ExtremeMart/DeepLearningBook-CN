\documentclass[a4paper,11pt]{book}
\usepackage{xeCJK}
\setCJKmainfont[BoldFont=STSong, ItalicFont=STKaiti]{STSong}
\setCJKsansfont[BoldFont=STHeiti]{STXihei}
\setCJKmonofont{STFangsong}

\usepackage{ctex}
\usepackage{bm}
\usepackage{amsfonts}
 
\begin{document}


\chapter{蒙特卡洛方法}{17}
\section{采样和蒙特卡罗方法}
随机化算法可以分成大致两类：拉斯维加斯算法和蒙特卡罗算法。拉斯维加斯算法总是准确地返回正确答案(或者报告失败)。这类算法假设随机量的资源，通常是内存或者时间。相反，蒙特卡罗算法返回答案时会带有随机量的错误。错误量通常可以通过扩展更多的资源(通常是运行时间和内存)被减少。对任意固定的计算方案，蒙特卡罗都可以给出一个近似回答。

机器学习领域中的许多问题都很困难，除了精确的确定性算法和拉斯维加斯算法，我们不能期待获得这些困难问题的精确答案。相反，我们必须使用确定性的近似算法或者蒙特卡罗近似，这两种方法在机器学习中是广泛存在的。本章，我们将讨论蒙特卡罗方法。

\subsection{采样和蒙特卡罗方法}
许多用于实现机器学习目标的重要技术都是基于从一些概率分布中抽取样本，然后用这些样本进行一定理想数量的蒙特卡罗估计。

\subsection{为什么采样？}
我们想要从概率分布中抽取样本有许多原因。采样用更少的代价，提供了一种灵活的方法来近似许多加和和积分。有时候我们使用采样来加速代价昂贵但是容易处理的加和，比如我们使用minibatches对整个训练代价子采样的情况。在其他情况，我们的学习算法需要逼近一个不容易处理的加和或者积分，比如对数模型的对数配分函数(log partition function)的梯度。在许多其他情况下，在我们想训练一个可以从训练分布中采样的模型的意义上，采样确实是我们的目标。


\subsection{蒙特卡罗采样的基本知识}
 当加和或者积分不能准确地被计算出来(比如，该加和具有指数级别数量的项，并且没有精确的简化)，我们经常会使用蒙特卡罗采样来逼近它。其思想是将加和或者积分看作是某种分布下的期望，然后通过相应的平均来近似该期望。令
 $$ s = \sum _{ x }^{  }{ p(\bm{x})f(\bm{x}) ={ E }_{ p }[f(\textbf{x})] }\eqno{(17.1)} $$
或者
 $$ s=\int { p(\bm{x})f(\bm{x})d\bm{x}= } { E }_{ p }[f(\textbf{x})]\eqno{(17.2)} $$
 是将要估计的加和或者积分，我们把它重新写成一个期望，这里$p$是随机变量\(\textbf{x}\)的概率分布(对加和而言)或者概率密度(对积分而言)。
 
 我们可以通过从$p$中抽取$n$个样本 $ { \bm{x} }^{ (1) },...,{ \bm{x} }^{ (n) }$，然后构建下面的经验平均来估计$s$：
 $${ \hat { s }  }_{ n } =\frac { 1 }{ n } \sum _{ i=1 }^{ n }{ f({ \bm{x} }^{ (i) }) } .\eqno{(17.3)}$$
这种近似可以由几个不同的性质来证明。首先，我们通过观察可以发现\(\hat { { s } } \)是无偏的，因此
$$\mathbb{E}[\hat{s}_n]=\frac{1}{n}\sum_{i=1}^{n}\mathbb{E}[f(\bm{x}^{(i)})]=\frac{1}{n}\sum_{i=1}^{n}s=s \eqno{(17.4)}$$
但是除此之外，大数定律告诉我们如果样本\({ \bm{x} }^{ (i) }\)是独立同分布，那么几乎可以肯定该平均收敛于期望值：
$$\lim _{ n\rightarrow \infty  }{ { \hat { s }  }_{ n }= } s, \eqno{(17.5)}$$
条件是每一项的方差\(Var[f({ \bm{x} }^{ (i) })]\)是有界的。为了看的更清楚，考虑\(n\)递增时\({\hat { s }  }_{ n }\)的方差。只要
\(Var[f({ \textbf{x} }^{ (i) })]<\infty \)，方差\(Var[{ \hat { s }  }_{ n }]\)递减且收敛于0:
$$ Var[{ \hat { s } }_{ n }]=\frac { 1 }{ { n }^{ 2 } } \sum _{ i=1 }^{ n }{ Var[f(\textbf{x})] }  \eqno{(17.6)}$$
$$=\frac { Var[f(\textbf{x})] }{ n } . \eqno{(17.7)}$$
这个方便的结论也告诉了我们如何用蒙特卡罗平均估计不确定或者等价地蒙特卡罗近似的预期误差量。我们计算\(f({\bm{x}}^{ (i) })\)的经验平均\footnote{更常说方差的无偏估计量，其中平方误差和除以n-1而不是n。}和经验方差，然后用样本数量\(n\)来除估计的方差获得\(Var[{\hat { s }  }_{ n }]\)的估计。中心极限定理告诉我们分布的均值\({\hat { s }  }_{ n }\)收敛到均值为\(s\)，方差为\(\frac { Var[f(\bf{x})] }{ n } \)的正态分布。这使得我们能够使用正态密度的累计分布来估计\({\hat { s }  }_{ n }\)的置信区间。

然而所有这些依赖于我们能否很容易地从基本分布\(p(\bf{x})\)进行采样，但是我们可能并不能总是这样做。如果从\(p\)中采样不合理时，另一种方法是使用重要性采样，我们会在17.2节介绍它。一种更常用的方法是构造收敛到感兴趣的分布的估计序列，这种方法是蒙特卡罗马尔可夫链(见17.3节)。

\section{重要性采样}

\section{马尔可夫蒙特卡罗方法}

\section{吉布斯采样}

\section{分离模式混合的挑战}

\end{document}